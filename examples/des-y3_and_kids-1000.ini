; This is currently set up to run a quick test sampler
; TODO add info on the polychord settings
[runtime]
sampler = test
verbosity = standard

[test]
save_dir=output/des-y3_and_kids-1000
fatal_errors=T

; We will carry out a joint Hybrid pipeline analysis of 
; DES Y3 xi_pm and KiDS-1000 COSEBIS including scale cuts (2'<theta_min<300')
[DEFAULT]
DATAFILE=likelihood/des-y3_and_kids-1000/DES-Y3_xipm_and_KiDS-1000_COSEBIs_2.0_300.0.fits
RUN_NAME = des-y3_and_kids-1000

[pipeline]
modules =   consistency camb extrapolate 
            fits_nz_des correlated_dz_priors fits_nz_kids photoz_bias_des photoz_bias_kids 
            fast_pt choose_des_ia IA 
            pk_to_cl_des add_intrinsic 2pt_shear shear_m_bias 2pt_like 
            choose_kids_ia IA 
            pk_to_cl_kids add_intrinsic cosebis cosebis_like
likelihoods = 2pt cosebis
values  = examples/des-y3_and_kids-1000-values.ini
priors  = examples/des-y3_and_kids-1000-priors.ini
extra_output =  cosmological_parameters/S_8 cosmological_parameters/sigma_8 
                cosmological_parameters/A_s cosmological_parameters/omega_m 
                cosmological_parameters/omega_lambda cosmological_parameters/cosmomc_theta 
                delta_z_out_kids/bin_1 delta_z_out_kids/bin_2 delta_z_out_kids/bin_3 
                delta_z_out_kids/bin_4 delta_z_out_kids/bin_5 
                delta_z_out_des/bin_1 delta_z_out_des/bin_2 delta_z_out_des/bin_3 
                delta_z_out_des/bin_4 
                data_vector/2pt_chi2 likelihoods/cosebis_like likelihoods/2pt_like
quiet = F
timing = F
debug = T

; Since CosmoSIS v3, the consistency interface allows for sampling over S8
; Here we set up the non-linear power spectrum
[consistency]
file = utility/consistency/consistency_interface.py

[camb]
file = boltzmann/camb/camb_interface.py
mode = all
halofit_version = mead2020_feedback  
neutrino_hierarchy = normal
lmax=2500
kmax=100.0
zmid = 2.0
nz_mid = 100
zmax = 6.0
nz = 150
background_zmax = 6.0
background_zmin = 0.0
background_nz = 6000
feedback=0

[extrapolate]
file = boltzmann/extrapolate/extrapolate_power.py
kmax = 500.

; Next we define the redshift bins and how we're going to marginalise over
; our uncertainty on these distributions
[fits_nz_des]
file = number_density/load_nz_fits/load_nz_fits.py
nz_file = %(DATAFILE)s
data_sets = source_des

; This module allows for correlated priors for KiDS given a covariance matrix
[correlated_dz_priors]
file = number_density/correlated_priors/correlated_priors.py
uncorrelated_parameters =   nofz_shifts_kids/uncorr_bias_1 nofz_shifts_kids/uncorr_bias_2 
                            nofz_shifts_kids/uncorr_bias_3 nofz_shifts_kids/uncorr_bias_4 
                            nofz_shifts_kids/uncorr_bias_5
output_parameters = nofz_shifts_kids/bias_1 nofz_shifts_kids/bias_2 
                    nofz_shifts_kids/bias_3 nofz_shifts_kids/bias_4 
                    nofz_shifts_kids/bias_5
covariance = likelihood/des-y3_and_kids-1000/nofz_covariance/SOM_cov_multiplied.asc

[fits_nz_kids]
file = number_density/load_nz_fits/load_nz_fits.py
nz_file = %(DATAFILE)s
data_sets = source_kids

[photoz_bias_des]
file = number_density/photoz_bias/photoz_bias.py
mode = additive
sample = nz_source_des
bias_section = wl_photoz_errors_des
interpolation = cubic
output_deltaz = T
output_section_name = delta_z_out_des

[photoz_bias_kids]
file = number_density/photoz_bias/photoz_bias.py
mode = additive
sample = nz_source_kids
bias_section = nofz_shifts_kids
interpolation = cubic
output_deltaz = T
output_section_name = delta_z_out_kids

; Here we are using the TATT modules for our IA model
; to allow for flexibility in extensions to our fiducial analyses
; The hybrid set-up uses NLA-z, with the non-NLA parameters
; in the TATT model are set to zero in the values file

[fast_pt]
file = structure/fast_pt/fast_pt_interface.py
do_ia = T
k_res_fac = 0.5
verbose = F

; In our fiducial analysis we allow for the DES and KiDS
; surveys to have independent IA parameters.  Call choose_ia_params
; and it updates the IA parameter name before the IA module is called
[choose_des_ia]
file =  intrinsic_alignments/choose_ia/choose_ia_params.py
suffix = des

[IA]
file = intrinsic_alignments/tatt/tatt_interface.py
sub_lowk=F
sub_const=F
include_s2_terms=F
do_galaxy_intrinsic=F
ia_model=tatt
Asigma8=F
linterp=F

; As DES and KiDS are assumed to be uncorrelated we can 
; calculate the likelihoods independently

; We start with DES
[pk_to_cl_des]
file = structure/projection/project_2d.py
ell_min_logspaced = 0.1
ell_max_logspaced = 5.0e5
n_ell_logspaced = 100
shear-shear = source_des-source_des
shear-intrinsic = source_des-source_des
intrinsic-intrinsic = source_des-source_des
intrinsicb-intrinsicb = source_des-source_des
verbose = F
get_kernel_peaks = F
sig_over_dchi = 20.
shear_kernel_dchi = 10.

[add_intrinsic]
file=shear/add_intrinsic/add_intrinsic.py
shear-shear=T
position-shear=F
perbin=F

[2pt_shear]
file = shear/cl_to_xi_fullsky/cl_to_xi_interface.py
ell_max = 40000
xi_type = EB
theta_file=%(DATAFILE)s
bin_avg = T
; these get
input_section_name = shear_cl  shear_cl_bb
output_section_name = shear_xi_plus  shear_xi_minus

[shear_m_bias]
file = shear/shear_bias/shear_m_bias.py
m_per_bin = True
; Despite the parameter name, this can operate on xi as well as C_ell.
cl_section = shear_xi_plus shear_xi_minus
verbose = F

; This is the 2pt_likelihood module.  It's all-singing all-dancing
; covering xi_pm, gamma_t and wtheta. 
; Don't be confused by the name "point mass" in the title.
; This addition only concerns the likelihood calculation of the GGL statistic
; which we're not analysing here (data_sets = xip xim)
[2pt_like]
file = likelihood/2pt/2pt_point_mass/2pt_point_mass.py
do_pm_marg = True
do_pm_sigcritinv = True
sigma_a = 10000.0
no_det_fac = False
include_norm = False
data_file = %(DATAFILE)s
data_sets = xip xim
make_covariance=F
covmat_name=COVMAT
; The scale cuts (angle_range_xi*_*_*) are listed in a separate file
; Here we use the LCDM-optimised scale cuts from Amon/Secco/Samuroff et al 2022
%include examples/des-y3-LCDM-optimised-scale-cuts.ini


; Now time to move on to KiDS
; First rename the IA parameters so they are independent of the
; IA parameters for DES.  If you want to use the same set of parameters
; for both surveys, remove both instances of this module and update
; the values file accordingly
[choose_kids_ia]
file = intrinsic_alignments/choose_ia/choose_ia_params.py
suffix = kids

[pk_to_cl_kids]
file = structure/projection/project_2d.py
ell_min_logspaced = 0.1
ell_max_logspaced = 5.0e5
n_ell_logspaced = 100 
shear-shear = source_kids-source_kids
shear-intrinsic = source_kids-source_kids
intrinsic-intrinsic = source_kids-source_kids
intrinsicb-intrinsicb = source_kids-source_kids
verbose = F
get_kernel_peaks = F
sig_over_dchi = 20. 
shear_kernel_dchi = 10.

[cosebis]
file=/Users/cheymans/CosmoSIS/2pt_stats/cl_to_cosebis/cl_to_cosebis_interface.so
theta_min = 2.0 ; default=1
theta_max = 300.0 ; default=100
n_max = 5 ; default=10
input_section_name = shear_cl
output_section_name = cosebis
;Wn_Output_FolderName = ${BASE}/modules/kids/cosebis/WnLog/ 
;Roots_n_Norms_FolderName = ${BASE}/modules/kids/cosebis/TLogsRootsAndNorms ; default is ./cosebis/TLogsRootsAndNorms
;Tn_Output_FolderName = ${BASE}/modules/kids/cosebis/Tn_Output_Folder ; default is ./cosebis/TpnLog/

[cosebis_like]
file = likelihood/2pt/simple_like.py
data_set = En n
data_file = %(DATAFILE)s
like_name = cosebis
